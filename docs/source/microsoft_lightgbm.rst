Using Microsoft's LightGBM
==========================

Thoughts on LightGBM:

#. LightGBM appears to be less deterministic than other gradient boosting implementations I've used (sklearn's GradientBoostingRegressor and GradientBoostingClassifier, and XGBoost). For a given data set, I've seen it achieve a certain level of accuracy with notably different feature importances than other implementations. The top 50 features will probably be a similar list to others, but the importances found from each of those features can be quite different.
#. LightGBM is sometimes noticeably quicker than XGBoost/scikit-learn. Particularly when it's the only thing running on the machine. But as soon as you kick off several models training together on the same machine, performance degrades rapidly compared to others. I haven't yet investigated too much, but I suspect this is because LightGBM actually uses all the cores on a machine, while scikit-learn uses only a single core for training and predictions.
#. LightGBM is nearly as fast as scikit-learn when making predictions on a single item at a time, meaning it is indeed ready for production deployments. This was one of my bigger concerns, as it is somewhat easier to optimize for batch processing than single-item processing (the overheard for parallelization jumps immediately to mind). Happily, I'm still able to get predictions from a complex pipeline using a complex LightGBM model in less than 1 millisecond each.
#. A trained LightGBM model, when saved to disk, is comparably sized to a trained scikit-learn model- just a few hundred KB. Again, easily small enough to be used in production without having to make any optimizations.
#. Happily, the process of training a model, saving it to disk, and loading it from disk back into memory again, all works flawlessly using the standard scikit-learn API.
#. LightGBM's python interface uses the standard scikit-learn API perfectly. auto_ml is obviously a somewhat complex project that relies heavily on the sklearn API. LightGBM was a drop-in replacement for all the other scikit-learn models I'm using. Huge kudos to the team for making this easy to use with the existing Python machine learning ecosystem.
#. Hyperparameter Optimization: LightGBM appears to be slightly more sensitive to hyperparameter optimization than I expected. I was easily able to overfit models on datasets of a few tens of thousands of items by simply bumping up n_estimators to 200. Conversely, using their default n_estimators of 20 led to pretty bad underfitting on another dataset we use of a few million items. From my initial explorations, num_leaves, n_estimators, and learning_rate can all have a pretty big impact on model accuracy. I saw very little movement from colsample or subsample. Again, because the team has so nicely implemented the scikit-learn interface thoroughly, LightGBM can be used with GridSearchCV out of the box.
#. Model accuracy. I've seen some mixed results here. Nothing as dramatic as the improvements over XGBoost that they're showing in the wiki. LightGBM's accuracy is about 2% (not two percentage points, two percent) better than scikit-learn's GradientBoostingRegressor for a large problem we're working on. But it somewhat lags behind XGBoostClassifier on a smaller dataset I'm working with. Overall, it appears to be somewhat comparable to slightly better than my benchmarks with other algorithms on our proprietary data. Though I'll be the first to say that more thorough testing (and particularly hyperparameter tuning) is in order here to accurately measure down to the single-percentage-point accuracies we're debating.
#. Data input format: So far I've been feeding in a standard numpy matrix with one-hot-encoded features, though the prospect of feeding in a pandas DataFrame with categorical features left as-is is certainly intriguing. From a quick look at the docs, it seems like simply converting the dtype of the categorical features to "category" will let you pass in a raw DataFrame. That's a pretty significant advantage over other implementations. This should noticeably reduce memory usage, likely impact computation time, possibly impact accuracy and feature_importances reporting. More importantly, it reduces the barrier to entry for machine learning even further. Yes, one-hot-encoding your data is a trivially easy step for experienced ML practicioners. But it's an annoyingly high hurdle for first-timers. Being able to simply pass in the DataFrame with their raw data should make this an even easier package for anyone to use.
#. Installation: Oh my gosh what a revelation. I run ML on a new MacBook Pro at work, my old personal MacBook Pro, and Linux in the cloud. I copy/pasted their installation instructions into the terminal in all three places, and the install worked nearly out of the box. I somewhat consistently ran into folder ownership permissions issues, even while using sudo, so I had to do some permutation on `sudo chown -R /path/to/folder $USER`. And I think there was some package I had to install on Linux that no other ML library I've used so far had required. So, for a grand total of 5 minutes of googling, and probably just 10 minutes of installation time, I had LightGBM up and running, parallelized, on 3 different machines. Compare this to XGBoost. When I tried to include XGBoost as a dependency for our dev environment, that's still the only time I've successfully pushed the envelope at work far enough that I broke everything. I remember celebrating wildly on the couch one night when I finally got XGBoost to run in parallel on my Mac after months of effort. Only to revert when I realized that it was noticeably slower running in parallel than it was single-threaded. I love XGBoost. I've submitted a number of PRs to the project. It's undeniably the benchmark for accuracy for many classes of machine learning problems. But it's an enormous pain to install in non-Linux environments. And let's face it- most of us do some amount of messing around on some local environment before jumping to the cloud or production, so this is a non-trivial benefit that LightGBM holds over XGBoost.
#. Open Source Community Management: This is another area where I'm impressed by LightGBM. I've submitted a number of issues and PRs and the team has been immediately responsive. They're at that lucky stage where they have an amazing, super-clean codebase that the original authors still know like the back of their hand. So debugging is quick, and contributing is easy. They've got all the integrations set up that you'd expect from a company like Microsoft. But the personal attention of somebody's pet project. Best of all, they're still very actively working on the project, so you can expect it to get better by the week. If you notice something in the docs that's unclear, or an undocumented feature you spy in the code, or anything else you want to contribute, I've found them very willing to receive both issues and PRs from the community.


LightGBM is baked into auto_ml now
----------------------------------

Just like XGBoost, if it is installed on your system, auto_ml will recognize that and use it as one of the default algorithms. If you don't have it installed, no sweat, auto_ml will still default back to scikit-learn's GradientBoosting or XGBoost.

To specify that you want to just use LightGBM, pass `model_names=['LGBMRegressor']` or `model_names=['LGBMClassifier']` to `.train()`


Thanks again to the team at Microsoft for not just the research to make LightGBM, but also for turning that research into what appears to be a production-grade open-source project.

